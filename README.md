# Markov-Decision-Processes

>Use command line "jython smallMDP.py" to run the small MDP problem. All the value iteration, policy iteration and Q-learning experiment are contained in there. Use command line "jython largeMDP.py" to run the large MDP problem.


>You will get the policy map from runnning the python file. And the resulting CSV file can be found under Solution>files>large_MDP or small_MDP. Use the CSV files you can plot the figures I showed in the report

In this report, I explored the Markov Decision Processing, which is different from the function approximation in the previous assignments. In mathematics, a Markov decision process (MDP) is a discrete-time stochastic control process. It provides a mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision-maker. MDP is useful for studying optimization problems solved via dynamic programming.
